# -*- coding: utf-8 -*-
"""Tehtävä 7: mnist_convnet

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ccP4PSF2Zr4vA-T3lYvPLFihWR9-61Oe

# Simple MNIST convnet

**Author:** [fchollet](https://twitter.com/fchollet)<br>
**Date created:** 2015/06/19<br>
**Last modified:** 2020/04/21<br>
**Description:** A simple convnet that achieves ~99% test accuracy on MNIST.

## Setup
"""
import numpy as np
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt

# Model / data parameters
num_classes = 10
input_shape = (28, 28, 1)

# Load the data and split it between train and test sets
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# Scale images to the [0, 1] range
x_train = x_train.astype("float32") / 255
x_test = x_test.astype("float32") / 255
# Make sure images have shape (28, 28, 1)
x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)
print("x_train shape:", x_train.shape)
print(x_train.shape[0], "train samples")
print(x_test.shape[0], "test samples")

print("Ennen konvertointia : \n",y_train[0:5])
# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)
print("Konvertoinnin jälkeen : \n",y_train[0:5])


"""
#Tehtävä 1:
Tulosta y_train ennen vektori luokkien konvertointia binääriksiksi ja konvertoinnin jälkeen. Konvertoinnin jälkeinen tuloshan on konvoluutioverkon odotettu oikea tulos. Miksi tulos on juuri tuollainen?

a.
y_train ennen konvertointia osoittaa kunkin kuvan arvon numeraalisessa muodossa harjoitusdatalle ja konvertoinnin jälkeen
tämä sama informaatio on neuroverkolle paremmassa muodossa eli konvertoinnin jälkeen meillä on kymmenen eri vastausta
ja niitä vastaava suurin korrelaatio eli arvo 1.

#Tehtävä 2:
a. Selitä, miksi yksi suodatus tarkoittaa 10 säädettävää parametria. Ensimmäinen suodatus käsittää 32 suodatinta ja säädettäviä parametreja tuossa vaiheessa on 320 eli yhdessä suodattimessa pitää sitten olla 10 säädettävää parametria, mutta mitkä nuo parametrit ovat?
b. Selitä, miksi ensimmäisen suodatuksen Conv2D jälkeen kuvan koko pienenee 28*28 kuvasta 26*26 kuvaksi.
c. Selitä, miksi kuvan koko puolittuu edellen MaxPooling 2D kuvassa.
d. Selitä, mistä tulevat toisen suodatuksen säädettävien parametrien luvut
e. Selitä, mistä tulee fully connected layerin säädettävien parametrien lukumäärät.

a.
Filtterin koko 3x3 plus bias arvo eli 3x3+1 = 10 ja 32 filtteriä 32 x 10 = 320

b. 
Kuva pienenee filtterin koon takia. Filtterin koko on 3x3 ja tämän takia kuva kapenee yhden pikselin verran, koska filtteri aloittaa nurkasta ja tulos ilmoitetaan filtterin keskelle, joten se kaventaa kuvaa yhden pikselin verran joka reunassa. 

c. 
Kuva käydään läpi 2x2 max poolauksella eli tältä alueelta otetaan maksimi arvo ja tämä talletetaan uuteen kuvaan. Tästä syystä kuva on puolet pienempi. 26/2 = 13

d. 
11x11 on eka poolauksen jäljiltä konvoloitu kuvakoko joka pienenee taas 3x3 filtterin takia yhdellä joka reunalta. Toisessa kerroksessa filttereitä on 64.
Joten parametrien määärä on: 
32 x 3 x 3 x 64 + 64 = 18496 
ensimmäisen tason filtterit x toisen tason filtterin koko x toisen tason filtterien määrä + toisen tason filtterien määrä

e. 
5 x 5 x 64 x 10 + 10 = 16010 
Kuvan koko x toisen tason filtterien määrä x viimeisen tason noodien määrä + viimeisen tason noodien määrä

## Build the model
"""

model = keras.Sequential(
    [
        keras.Input(shape=input_shape),
        layers.Conv2D(32, kernel_size=(3, 3), activation="relu"),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Conv2D(64, kernel_size=(3, 3), activation="relu"),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Flatten(),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation="softmax"),
    ]
)
model.summary()

"""## Train the model"""

batch_size = 128
epochs = 15

model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])

model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)

"""## Evaluate the trained model"""

score = model.evaluate(x_test, y_test, verbose=0)
print("Test loss:", score[0])
print("Test accuracy:", score[1])


#Mallin ajaminen 60000 kuvalle
x_predict = model.predict(x_train)

"""
Tehtävä 3:
Tee koodi, jonka avulla voit löytää 60000 kuvan joukosta ne kuvat, joita CNN ei kykene tunnistamaan oikein.
"""


#Tulosten vertailu ja listaaminen omaan taulukkoonsa
incorrect = np.empty(0)
for i in range(len(y_train)):
    if not np.argmax(y_train[i]) == np.argmax(x_predict[i]):
        incorrect = np.append(incorrect,i)

#Väärin menneiden tulosten graafinen esitys
column = 10
row = int(len(incorrect))
for x in range(row):
    plt.figure(1,figsize=(30,90))
    plt.subplot(row//column+1,column,x+1)
    plt.imshow(x_train[int(incorrect[x])].reshape(28,28),aspect='auto',cmap='gray')
    
#Linkki tehtävään google colabissa: https://colab.research.google.com/drive/1ccP4PSF2Zr4vA-T3lYvPLFihWR9-61Oe#scrollTo=Jl80V0xJxycx